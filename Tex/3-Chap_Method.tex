\chapter{基于深度学习的光照估计方法}\label{chap:illumination-estimation}
\section{引言}
从有限的图像信息估计出整个场景的光照分布是一个复杂的问题。
首先，图像的视野范围比较有限，
例如一张视场角（FOV）为60°的照片所拍摄到的区域，在其对应的全景图中占比不足6\%。
此外，一幅图片是光照分布、场景几何结构、物体材质、摄相机参数等多个单位之间的复杂交互结果
（公式~\ref{eq:complex-interaction-result-2}）。
\begin{equation} \centering \label{eq:complex-interaction-result-2}
Image = ComplexInteraction(Light, Geometry, Material, Camera)\end{equation}
通过公式\ref{eq:complex-interaction-result-2}可以看出，
在其它三个信息未知的情况下，从图像（Image）反推出光照（Light）是一个严重的不适定（ill-posed)问题。
不仅如此，在不同的条件下拍摄的彩色图像可能存在很多误差。
例如图像中的过曝光/欠曝光区域、相机畸变、不正确的白平衡等。
这些都会对光照估计造成一定程度的干扰，增加光照估计的难度。

为了降低问题的难度，研究者们尝试对该问题进行约束或简化。在利用传统方法估计光照时，简化的方式通常是增加输入的信息或者减少要估计的光照模型规模。一部分工作使用更多的输入信息辅助估计场景光照。例如
深度信息\cite{knecht2012reciprocal,meilland20133d,zhang2016emptying,barron2013intrinsic}
几何信息\cite{ramamoorthi2001signal,sato2003illumination,li2003multiple}
多张图片\cite{sato1999acquiring,nishino2001determining,yu2006sparse}
先验知识\cite{nishino2004eyes,barron2015shape,lopez2010compositing}
用户标记\cite{lopez2010compositing,karsch2011rendering}等等。另一部分工作通过使用低维的光照表示模型来简化光照估计问题，例如使用球形谐波函数（SH)来拟合场景光照\cite{ramamoorthi2001signal,kemelmacher20113d,garrido2013reconstructing, knorr2014real,
li2014intrinsic,barron2015shape, rematas2016deep}、使用小波函数近似场景光照\cite{okabe2004spherical}、光照分布简化为若干个点光源的集合\cite{sato1999acquiring,  panagopoulos2011illumination, wang2002estimation, li2003multiple, sato2003illumination}、使用基于物理的室外光照模型\cite{lalonde2008does, lalonde2010sun, lalonde2012estimating, sunkavalli2008color}等。

近年来，一些研究者尝试将深度学习方法应用在光照估计问题当中。Hold-Geoffroy等人\cite{hold2017deep}搭建了一个深度卷积神经网络从室外图片中恢复出室外场景的参数化光照模型。Gardner等人\cite{gardner2017learning}从室内图片中直接估计HDR全景图像。这两个方法是目前单图片光照估计工作中最先进的方法。不过，目前已有的深度学习方法也有一定的局限性。训练一个鲁棒的神经网络往往需要大量的数据，而目前用于光照估计问题的数据集比较有限，主要包括：大规模的低动态范围全景数据集（SUN360\cite{xiao2012recognizing}等）和中小规模特定场景的高动态范围全景数据集（Laval Indoor等\cite{gardner2017learning}）。这些数据集在规模和质量上很难同时到达训练深度神经网络的要求。

在这样的背景下，本文在光照估计的两个方向上开展研究。
其一是构建一个具有一定规模和质量光照估计的数据集。
这样的数据集不仅能被用来训练更加鲁棒的光照估计网络，也可以被应用到其它多种相关的深度学习问题当中，
上一章节对这一部分工作进行了详细的介绍。
其二是在已有数据集和本文构建的数据集基础上，深入探索基于深度学习的光照估计方法，
对其中的网络结构，网络参数，损失函数，光照表示等多个模块进行细致的对比和研究。
这是本章节的所述工作的主要目标。

本章的工作内容和创新贡献主要有以下几点：
\begin{itemize}
    \item 首次提出使用前两张相对视角的图片作为光照估计的输入。这两张图片多由相机的前后置摄像头拍摄，使用前后摄像头同时拍摄两张照片不仅不会增加获取图片的步骤，还可以极大地降低光照估计的难度。现代移动设备几乎都包含前后至少两个摄像头，因此本文所提方法对于智能手机应用来说有着很大的实际意义。
    \item 构建了一个基于深度学习的光照估计网络模型，该网络模型使用两张图片作为输入，估计预测出场景中光照对应的球形谐波系数，该模型在光照估计问题中非常有效，目前已经取得了超过state-of-the-art的结果。
    \item 提出了一个新的损失函数 - Render Loss，该损失函数巧妙地利用了SH的特性，将部分渲染过程置于神经网络中，这样可以在渲染结果上添加监督信息，指导网络训练。提出的方法算法简洁但非常有效，极大地提高了光照估计的表现。
    \item 对提出的光照估计深度学习模型和损失函数进行十分详尽的实验和分析，对于光照估计网络结构和训练过程中各个模块，通过几十组对比实验深入探索了使用不同网络结构的特点和对结果的影响，促进了对基于深度学习光照估计的理解。
\end{itemize}

\section{相关工作}
\subsection{深度学习}
卷积神经网络（CNN）最早由Lecun等人\cite{lecun1998gradient}在1998年提出. 随着计算机显卡性能的提高和超大规模数据集（例如ImageNet\cite{deng2009imagenet}，ShapeNet\cite{chang2015shapenet}）的建立，深度学习在多个领域成为了一个强力的工具。近年来，为了解决各种类型的问题，卷积神经网络结构层出不穷，例如AlexNet~\cite{krizhevsky2012imagenet}, VGG~\cite{simonyan2014very}, ResNet~\cite{he2016deep}。它们在许多视觉问题中超越了传统方法中取得的非常好的成绩，例如物体检测\cite{girshick2014rich}、图像分类\cite{krizhevsky2012imagenet}、图像分割\cite{ronneberger2015u}等等。近期，卷积神经网络也被应用到了传统的图形学问题中，例如渲染降噪\cite{chaitanya2017interactive}、人脸模拟\cite{karras2017audio}等等，都取得了很好的结果。
\subsection{传统光照估计方法}
传统方法估计光照时，常常通过增加输入信息或者简化光照模型来降低求解难度。Sato等人\cite{sato1999acquiring}、Nishino\cite{nishino2001determining}等人、Yu\cite{yu2006sparse}等人使用多张图片作为输入。Knecht\cite{knecht2012reciprocal}等人、Meilland\cite{meilland20133d}等人、Zhang等人\cite{zhang2016emptying}、Barron和Mailk\cite{barron2013intrinsic}等使用额外的深度信息估计光照。还有一些工作使用已知的几何信息辅助估计光照\cite{ramamoorthi2001signal, sato2003illumination, li2003multiple}。
另外一部分工作通过使用低维的光照表示模型来简化光照估计问题，例如使用球形谐波函数（SH)来拟合场景光照\cite{ramamoorthi2001signal,kemelmacher20113d,garrido2013reconstructing,
knorr2014real,li2014intrinsic,barron2015shape, rematas2016deep}。通过使用SH，场景光照的低频部分可以使用少量的系数（通常为9-16组，约27-48个）来近似，这极大地减少了光照估计的难度，与之类似，Barronhe和Malik\cite{okabe2004spherical}在光照估计问题中使用小波函数来近似场景光照。还有一些光照估计工作\cite{sato1999acquiring,  panagopoulos2011illumination, wang2002estimation, li2003multiple, sato2003illumination}将光照分布简化为若干个点光源的集合，进而将光照分布估计问题转化为预测光源数量、位置和大小的问题。对于室外场景中的光照估计问题，使用基于物理的室外光照模型\cite{lalonde2008does, lalonde2010sun, lalonde2012estimating, sunkavalli2008color}可以使用更少的参数表示更精确的室外场景光照信息。
\subsection{基于深度学习的光照估计方法}

近期许多工作尝试使用深度学习解决光照估计问题。和传统方法类似，使用深度学习求解光照估计问题时也会借助一些辅助信息、探测物等。Calian等人\cite{calian2018faces}使用人脸作为光探测物，搭建了神经网络从照片恢复出室外场景的光照。Yi等人\cite{yi2018faces}搭建了一个高光提取神经网络和阴影反照率估计网络，来从人脸照片中恢复出室内外场景的光照信息。
Georgoulis等人\cite{georgoulis2016delight}使用真实反射图作为输入，用两个不同的CNN结构将图片分解为材质变量和光照变量。之后Geogoulis等人\cite{georgoulis2016natural}又尝试利用深度学习从包含多种已知材质的物体图片中恢复出反射图和光照分布。Mandl等人\cite{mandl2017learning}、Weber等人\cite{weber2018learning}也是借用了已知的物体几何恢复出场景光照。虽然这些光照方法和传统方法类似，也借助了一些额外的信息。但通过将传统方法中复杂的算法步骤替换为用深度学习求解，往往能取得更好的结果，这通常得益于大规模的训练数据。

使用深度学习求解光照估计问题时，也会使与传统方法中相同的光照表示模型。例如基于物理的Sun-sky模型\cite{hold2017deep}， 球形谐波函数模型\cite{mandl2017learning}等。深度学习在学习输入图像的特征时，非常有用，因此Weber等人\cite{weber2018learning}结合深度学习，使用自编码器（auto-encoder）对光照分布进行建模，使用卷积神经网络将场景编码为包含少量系数的隐变量，为光照估计问题中光照的表示提供了新的思路。

考虑到CNN强大的学习能力，最近一些方法尝试使用深度学习工具直接从单张图片中恢复整个场景的光照分布。
Holdgeoffroy等人\cite{hold2017deep}搭建了一个深度卷积神经网络从室外图片中恢复出室外场景的参数化光照模型。Gardner等人\cite{gardner2017learning}从室内图片中直接估计HDR全景图像。这两个方法是目前单图片光照估计工作中最先进的方法。
由于HDR全景数据有限，这些方法设计了一个光源探测系统，将大量的低动态范围全景图转化为粗糙的高动态范围全景图用于训练。

\section{问题求解范围}
从视角有限的单张图片预测完整的场景光照分布是一个复杂的问题，目前已有的算法大多增加输入信息或简化光照模型两个方面来降低问题的难度。在增加输入信息方面，许多工作使用多张图片、或使用额外的深度信息、或使用已知的几何信息等。这种方式虽然可以简化光照估计问题的难度，提升光照估计效果。不过增加输入信息意味着要使用额外的设备（例如如借助深度相机）或更多的获取步骤（例如多次拍摄）。因此，需要在获取降低输入信息获取步骤与提升光照估计效果之间找到一个平衡点，即划定输入信息的规模，使得使用这个规模的信息不仅不需要过多地增加额外的步骤和设备，而且可以更大的提升光照估计的表现。

现代智能设备中的前后摄像头拍摄的成对照片可以作为这样的一个平衡点。在图片方面，这些设备通常都具有前后两个摄像头，经过在各类手机的验证，大部分现代智能设备的这两个摄像头均可以同时运行（常用的手机应用很少需要同时用到前后摄像头，因此并没有应用同时开启前后摄像头，但经过在多种机型验证，这确实是可以简单的做到的）。因此可以在同一时刻使用现代智能设备的前后置相机拍摄两幅图片。这和拍摄一幅图片的步骤完全相同，用户既不需要多余的拍摄步骤，更不需要使用额外的设备。同时，小节\ref{sec:experiment}中的实验也表明，使用前后两个视角的图片作为输入时，能够极大地提高光照估计的效果。

光照估计的输入决定了光照估计问题的求解范围，例如使用单张图片作为输入时，光照估计问题的求解范围是图片，使用额外的深度信息辅助估计光照时，问题的求解范围则为RGBD图像。使用成对的图片作为输入时，问题的求解范围依然是图片，而且同时拍摄两张图片并不会增加获取步骤。据此本文提出使用现代设备前后相机拍摄的两幅图片作为光照估计方法的输入，这也是目前所有的光照估计工作中首次使用这样的输入信息，这对于光照估计问题在智能设备中的应用来说有着很大的实际意义。

\section{光照分布的球形谐波表示}
使用简化的光照分布近似模型是降低光照估计问题的另一个思路。目前已有的光照估计问题中，较为常见的近似方式通常包括球形谐波（SH）函数近似，点光源集合近似，小波函数近似，以及基于物理模型的室外光照近似。类似于这些工作，本文也选择使用SH来近似场景的光照。光照的SH近似最早由Sloan等人在\cite{sloan2002precomputed}提出，这种近似方式有很多优点：一方面SH系数小巧而且高效，场景的光照可以使用少量的系数近似，通过预计算一部分信息，SH渲染过程能够很容易达到实时。另一方面SH在近似场景光照时可以保留绝大部分的低频信息和小部分的高频信息，使用真实光照和SH系数近似的光照在渲染漫反射物体时差别非常小。通用、高效是本文和目前已有的大部分光照估计工作选取球形谐波函数的主要原因。

使用SH近似场景光照需要用到SH基函数。勒让德多项式（Legendre polynomial）是SH的核心，这是一个定义球表面上的，类似于傅里叶变换的数学系统。SH基函数通常是在虚数上定义的，不过在近似光照时，只考虑近似球体上的实函数。SH基函数函数通常由符号y表示。
\begin{equation}
y^m_l(\theta, \phi)=\left\{
    \begin{array}{lcl}
        \sqrt{2}K^m_lcos(m\phi)P^m_l(cos\phi) & & {m<0}\\
        \sqrt{2}K^m_lsin(|m|\phi)P^|m|_l(cos\phi) & & {m>0}\\
        \sqrt{2}K^0_lP^0_l(cos\phi) & & {m=0}
    \end{array} \right. 
\end{equation}

其中$l$表示基函数的阶，$-l \leq m \leq l$；$P$为勒让德多项式，$K$为归一化系数：
\begin{equation}
    K^m_l=\sqrt{\frac{(2l+1)}{4\pi}\frac{(l-|m|)!}{(l+|m|)!}}
\end{equation}
图\todo{图片}是引自\cite{green2003spherical}的图片，展示了SH基函数的大致形状。

场景的光照分布可以映射到一个球面上，即$L(s)$, $s$ 表示从球心到球面上的一个方向。
通过SH基函数可以将球面上的光照分布映射为SH系数:
\begin{equation}
    c^m_l = \int\limits_{S}f(s)y^m_l(s)ds
\end{equation}

根据$l$和$m$的关系，可以看出，$l$阶SH需要$2l$个系数。将光照映射到$n$阶时，共需要$n^2$个SH系数。
因此对于$n$阶的SH系数，可以将$c$展开为一维向量$c_i, 0 \leq i < n^2$
球面上的$n$阶SH近似光照$\tilde{L}(s)$可以通过SH系数计算：
\begin{equation}
    \tilde{L}(s)=\sum_{l=0}^{n-1}\sum_{m=-l}^{l}c^m_ly^m_l(s)=\sum_{i=0}^{n^2}c_iy_i(s)
\end{equation}
HDR全景图像映射为SH系数时，需要先将HDR全景图像投影到球面上，随后再将球面上的光照分布映射为一组SH系数。
\todo{图片}展示了使用不同光照的SH阶数近似渲染的漫反射物体结果，可以看出使用3阶SH的渲染结果已经和真实值非常接近。考虑到深度神经网络强大的学习能力，本文使用了4阶SH来近似场景光照，此外由于光照信息包含了三个通道，因此共需要48个SH系数($4^2\times3$)。
\section{光照估计网络结构}
在本文的光照估计方法中，输入为两幅由前后置相机拍摄的相对图片，目标输出为48个SH系数。因此需要搭建一个从两幅图片预测出48个参数的深度卷积神经网络（CNN)。
该网络需要从图片中提取特征图，并使用全连接层回归出用以表示光照的SH系数。
本文仔细地设计了光照估计的卷积神经网络结构，如图\todo{图片}所示。
该网络结构主要包含两个部分：第一部分提取两幅输入图像的特征，第二部分融合这些特征并预测SH系数。 

本文构建的HDR数据集虽然有近千张，但是对于训练神经网络来说还是略显不足，因此考虑使用预训练的网络和参数提取图像特征。在调研时发现，场景的光照分布与场景的类型密切相关（例如， 室外，室内，白天，夜晚等），因此在特征提取部分采用了Zhou预训练的场景分类网络\cite{zhou2017places}，这个网络在大规模数据集上进行了训练，能够用来提取图像特征。 在预测回归阶段，提取的两组图像特征在通道维度被拼接在一起。随后卷积层和FC层以预测最终的SH系数， 表\todo{表格}展示了详细的网络结构，除了最后一层外，其它层之后都有batch normalization和leaky RELU激活函数层。
\section{损失函数}
在训练神经网络时，损失函数的意义重大。合理的损失函数能够加快网络的收敛，提高网络的表现。本文通过分析SH和渲染结果之间的差异，提出了一个新的用于优化光照估计神经网络的损失函数。
\subsection{球谐参数损失函数} 为了预测的SH系数与真实SH系数之间才差异，一个比较直观的做法是使用MSE作为损失函数。不过在SH系数中，不同阶的参数个数是不同的，每一个SH系数在近似光照时所占的权重并不相同。为了平衡这种不均衡的权重，需要先在每一阶的SH系数上计算MSE，然后再不同阶之间做均值。这种均衡化之后的SH距离可以作为训练网络的损失函数。SH Loss的定义如公式\ref{eq:sh-loss}
\begin{equation}
    \mathcal{L}_{SH} = \frac{1}{n}\sum_{l=0}^{n-1}(\frac{1}{2l+1}\sum_{m=-l}^{l}(SH^m_l - SH^m_l)^2))
    \label{eq:sh-loss}
\end{equation}
其中，$n$为近似光照所使用的SH的阶数，该公式为每个颜色通道上的SH Loss，在整个颜色空间中对每个通道的Loss做均值即可。

\subsection{渲染结果损失函数} 虽然MSE是评估两个向量之间距离的常用指标，但是对于光照估计问题来说，仅用MSE来作为损失函数优化SH系数是不够的。实际上，较低的SH误差并不能保证对应光照的渲染结果足够好。SH系数上的微小差异也可能会导致渲染结果上非常大的误差。在图片\todo{图片}中，每隔5\doge地旋转一幅HDR全景图，计算对应的SH系数，随后分别使用旋转后的HDR全景图和SH渲染一个物体并计算他们之间的差异。从图中可以看出，经过5\doge的旋转，虽然SH之间的差异非常小，但是渲染结果的变化却十分巨大。

因此本文提出一种Render Loss，意图在训练光照估计神经网络时，增加渲染结果上的监督信息。具体的做法是先将一些3D物体渲染为一张SH Map（渲染方式参考\cite{green2003spherical}）。使用SH Map与近似光照的SH系数可以计算出该光照下物体的渲染图像：
\begin{equation}
    R(SH, x, y, c) = \sum^{n^2}_{i=1}SHMap(x,y,i)*SH_{c,i}
\end{equation}

其中$n$为近似光照所使用的SH的阶数，$c$表示渲染图的某个通道, $(x, y)$为渲染结果和SH map的图片坐标。

上述公式表明，在预计算SH map之后，SH系数与渲染结果之间是线性的乘加关系，可以将其添加在神经网络中并计算梯度。因此可以定义Render Loss：
\begin{equation}
    \mathcal{L}_{render} = \frac{1}{W\times H\times C} \sum_{x=1}^{W}\sum_{y=1}^{H}\sum_{c=1}^{C}(R(SH,x,y,c)-R(\hat{SH},x,y,c))^{2}
\end{equation}

其中$R(SH,x,y,c)$ SH的渲染结果在坐标$(x,y)$，通道$c$的颜色值。$W, H$ 分别是渲染图像的宽高，$C=3$表示RGB三个通道数。
最终的损失函数定义为SH Loss和Render Loss的加权和：
\begin{equation}
    \label{eq:loss-function}
    \mathcal{L} =w_{1}*\mathcal{L}_{SH}+w_{2}*\mathcal{L}_{render}
\end{equation}

 其中 $w_1$ 和 $w_2$ 是用来平衡 $\mathcal{L}_{sh}$和$\mathcal{L}_{render}$权重的超参数。
\section{实验结果与评估}\label{sec:experiment}
为了验证本文的深度光照估计方法的有效性，本文设计了光照估计实验，对比了提出的光照估计方法与当前最先进的（SOTA）方法，实验结果表明本文方法在室内室外场景下均优于其他方法。同时，该方法在真实场景下进行了测试，使用预测光照的渲染结果能够达到理想的水平。
\subsection{实现细节}
\begin{itemize}
    \item \textbf{数据准备} 通过拍摄和收集，本文构建了包含近千张HDR全景图的数据集。在训练光照估计网络时，需要使用这些HDR全景图生成大批量的训练和测试数据。首先HDR全景图按照90\%, 5\%, 5\%的比例划分为训练集，测试集和验证集，训练集用来训练光照估计网络，测试上的结果用来指导调整网络结构和超参数。验证集用以评估光照估计网络的表现。
    
    接下来生成输入图片。首先将划分后的每张HDR全景图映射到单位球体的表面，并将视点置于球心，然后选取一个视线方向$(\theta, \phi)$。根据球面坐标系的定义可知其相对方向为$(\pi-\theta, -\phi)$，这两个方向上的视图可以视为前后摄像头拍摄的两幅照片。由于大部分智能设备的前后置相机并不会很好的对齐，在选取相对方向时，需要在垂直和水平方向分别添加一个标准差为5\doge的高斯扰动。同时，为了通过数据增强提高光照估计神经网络的泛化能力，在提取图片时会使用不同的曝光值$e$，即HDR全景图乘以$2^e$，其中$e$服从[-1.5, 1.5]之间的均匀分布。

    在从$(\theta, \phi)$和其相对方向提取图片后，在该方向上的SH系数也会相应的提取出来，该实验使用4阶的SH来近似场景光照，因此这里SH的系数共有48个（$4^2\time3$通道）。
    
    对于每张HDR全景图，会均匀地随机128个方向来提取图片和SH系数，在过滤掉过度曝光和欠曝光的图片后，用于训练光照估计网络的图片/SH系数数据对大概为12万组。此外，数据的划分是在HDR全景数据集上进行的，所以同一幅HDR图像不会同时出现在训练集、测试集或验证集中，规避了训练集和测试集中包含相同图片的可能。
    \item \textbf{训练细节}训练光照估计网络的硬件平台、操作系统、优化器、学习率等参数列于表\ref{table:traning-details}中。另外在训练时，用以平衡$\mathcal{L}_{sh}$和$\mathcal{L}_{render}$权重的$w_1$ 和 $w_2$被设为0.8和0.2，这是通过探究实验\ref{sec:ablation-study}获取的最佳配置。
    \begin{table}[htbp]
        \centering
        \begin{tabular}{r|l}
            \hline
            项目 & 配置\\
            \hline
            硬件平台 & 处理器Intel6800k， 内存16G，显卡NVIDIA GTX 1080\\
            操作系统 & Ubuntu 18.04 64位\\
            优化器    & RMS Prop 优化器\\
            批大小    & 16，又称batch size\\
            初始学习率 & 0.0005 \\
            学习率衰减 & 每训练2万步，学习率乘以0.9\\
            训练时间 & 100个epoch，约1200万对数据，750万步\\
            \hline            
        \end{tabular}
        \caption{
            \label{table:traning-details}
            光照估计网络的训练细节。
        }
    \end{table}
    \item \textbf{评估方式} 评估光照估计的常用方式是计算真实渲染结果（通常是图像）与估计光照渲染结果之间的差异。衡量图片之间距离的常用度量指标有均方差(mean squared error，MSE)、均方根（root mean squared error, RMSE）、平均绝对误差差（mean absolute  error，MAE）、结构相似性（structural similarity， SSIM）、结构差异性（structural dissimilarity, DSSIM）、峰值信噪比（peak signal to noise ratio，PSNR）等等。与现有的光照估计方法类似，本实验中选用的指标为RMSE和DSSIM。对于验证集中的每一对数据，真实的渲染结果使用原始的HDR全景图进行渲染，将其作为ground truth与使用预测SH渲染的结果对比，计算它们之间的RMSE和DSSIM，通过对验证集上所有数据的RMSE和DSSIM均值作为评价光照估计方法的最终指标。
\end{itemize}
\subsection{与最先进方法的对比}
本文与目前的两个最先进的（state-of-the-art， SOTA）光照估计工作进行了对比:Hold-Geoffroy等人\cite{hold2017deep}的室外光照估计工作，Gardner等人\cite{gardner2017learning}的室内光照估计工作。前者通过卷积神经网络，从室外图片预测出sun-sky模型\cite{hovsekhovsek2013adding}的几个物理参数，进而达到估计光照的目的；后者通过在大规模低动态范围全景图上预训练、在小规模室内高动态范围全景图上微调（fine-tune），构建了一个从室内图片预测场景光照的深度学习模型；这两个工作都提供了从图片到HDR全景图的在线应用，上传一张图片后就可以获取估计的光照分布。在验证集上，本文方法与这两个工作进行了对比，数值结果如\todo{表格所示}。可以看出，无论是室外场景还是室内场景，本文方法在RMSE和DSSIM上均明显优于其它工作。图\todo{图片}是本方法和两个SOTA方法的可视化对比，结果显示是用本文方法估计的光照渲染的3D物体更接近真实的渲染结果。
\subsection{在真实数据上的表现}
本文的光照估计方法使用视角相对的两张图片作为输入，这对于具有前后相机的现代设备来说有着实际的意义。因此本文测试了该光照估计方法在真实场景中的表现。主要的设备是一部普通的智能手机和一台全景相机。首先使用智能手机的前后置相机同时拍摄两张图片，然后使用全景相机在同样的位置获取HDR全景图。拍摄的两张图片输入到光照估计网络，随后使用预测的SH系数渲染一个3D物体插入到图像中，最后将此结果与使用HDR全景图渲染的结果进行对比。图\todo{图片}展示了本文方法在真实场景中的表现，可以观察到本文方法在多种场景下均能取得较好的结果。
\section{深入研究光照估计网络}\label{sec:ablation-study}
本文方法中的网络结构包含了多个模块：特征提取模块，特征融合模块，光照估计模块等等，训练过程中也有多个可调的参数，例如损失函数中的权重系数$w_1$和$w_2$。这些模块和参数的选取与使用方式都在一定程度上影响了光照估计效果。本节通过几十组详细的实验，探究这些模块、参数对光照估计结果的影响，从可视结果与数值结果上就行定性和定量的分析。这些实验和分析对以后的深度学习、光照估计工作来说有着一定的指导意义。
\subsection{探究特征提取模块}
在光照估计网络中，特征提取模块使用的是Zhou等人\cite{zhou2017places}的场景分类网络结构。不过Zhou等人\cite{zhou2017places}在进行场景分类时，使用了多种类型的网络模型，例如AlexNet\cite{krizhevsky2012imagenet}，GoogleNet\cite{szegedy2015going}，VGG-16\cite{simonyan2014very}等。即使使用同样的数据和训练方式，这些网络在场景分类时也有着不同的表现。使用不同的网络作为光照估计网络中的特征提取模块，也会极大地影响光照估计的效果。因此需要通过实验对比使用不同的网络结构时结果的差异。

对于同一个特征提取网络，预训练的网络参数的使用方式也有多种：
\begin{itemize}
    \item \textbf{Freeze}，固定住预训练好的网络参数。这种方式将直接使用预训练的参数进行特征提取，在训练整个网络时，这部分参数保持固定，不参与变量的更新。
    \item \textbf{Fine-tune}， 以预训练的网络参数作为初始参数。在训练的过程中与网络中的其它部分一起计算梯度，更新参数。
    \item \textbf{From scratch}，不实用预训练的参数。这种方式只使用引入的网络结构，网络中变量使用随机的初始值，并参与网络中的变量更新。
\end{itemize}
对于不同的问题、模型、训练集，选取合理的预训练参数引入方式十分重要。

本节设计了九组实验，分别使用不同的网络结构和参数引入方式组合。表格\todo{表格}展示了这些方式在验证集上的数值结果，选取的两个评价指标是渲染结果上的RMSE和DSSIM。可以看出，对于不同的网络结构，最佳的预训练网络参数的引用方式并不相同。对于GoogleNet和VGG-16这两种结构来说，最好的方式是fine-tune预训练参数。而对于Alexnet来说最好的使用方式是Freeze，即固定住预训练参数，其中的变量不参与参数更新。图\todo{图片}展示了在不同的参数引入方式下，光照估计的结果对比，可以看出固定预训练网络参数的方式更接近真实的渲染结果。

不过值得一提的是，目前的结果只是在当前数据集上的表现。由于数据集规模限制，如果不使用预训练参数，网络可能难以从有限的数据中学到足够好的特征选取方式，因此固定预训练参数的方式表现最好。在数据集扩充以后，最佳的参数引入方式极有可能发生变化，当然，这需要在以后研究中使用更大规模的数据进行更详细的验证。

在目前的数据集上，表现最好的网络结构与参数引用方式组合是使用固定参数的Alexnet，因此后续的探究中均使用这种结构和方式进行对比实验。
\subsection{探究特征融合方式}
本文的光照估计网络输入是两张图片，通过预训练的网络可以从这两幅图片中提取特征图像。特征图像进行合并才能输入到后续的网络中，因此需要选择合理的特征融合方式。常见的特征图融合方式都是在通道层进行的，例如通道层拼接、通道层相加、通道层相减、通道层相乘等等。深度学习任务中使用做多的特征融合方式是通道层拼接（concatenate)。

在该问题中，特征图在通道层相加是不合理的。由于两幅图片使用的是完全相同的特征提取网络，所以当融合方式是相加时，交换两幅图片产生的结果不会有任何变化，但实际上这两个方向的光照是截然不同的，这显然不合常理。而拼接和相减却没有这个问题，因此本节实验验证了这两种方式对光照估计结果的影响，实验结果如图\todo{图片}所示，可以看出通道层拼接在各种网络结构和评价指标上均优于通道层相减。
\subsection{探究损失函数}
为了探究提出的render loss对光照估计结果的影响，并找到最优的损失函数权重系数$w_1$，$w_2$(公式\ref{eq:loss-function}），本节设计和实现了十几组实验，详细地对比了使用不同的$w_1$，$w_2$的损失函数，对于光照估计的影响。表\todo{表格}列出了详细的实验结果，其中使用$w_1=0.8$，$w_2=0.2$的损失函数能够达到最好的结果。图\todo{图片}的可视结果也表明，相较于只使用一类损失函数，综合使用两个损失函数可以得出更加接近真实值的效果。

需要注意的是，在训练时计算render loss所用的三维物体，与在测试时渲染的三维物体是不相同的。因此增加render loss能够提升效果的原因并不是3D物体的先验知识，而是render loss本身对于渲染过程和场景光照的关注。这也是只使用render loss的效果比较差的原因之一。
\subsection{探究光照估计性能}
本文所提出的关照估计算法非常适合现代智能手机应用，因此模型的性能也是需要考量的一个因素。本文测试了光照估计的性能表现，在普通的消费级桌面显卡NVIDIA GTX 1080上，从一对图片估计出SH系数耗时0.0391秒，在CPU（INTEL i76800k）上则需要0.3039s。虽然该耗时无法在大量的低端设备达到实时，但是通过优化和裁剪仍然可以达到不错的交互速度。此外，目前的网络结构使用的是AlexNet，虽然该模型在当前数据集上最好的选择，但随着数据集规模的不断增加，一些轻量级的网络可能会更加合适。同时随着现代智能设备处理器性能的不断提高，该方法有望在移动设备中达到实时交互的效果。
\section{讨论}
本章提出了一个从图片恢复场景光照的深度学习模型。该模型使用现代智能设备的前后相机拍摄的图片作为输入，预测出场景光照分布对应的球形谐波系数。该网络由特征提取模块，特征融合模块，光照估计模块组成，其中特征提取模块引用了Zhou\cite{zhou2017places}的网络结构和参数。结合创新提出的损失函数render loss，该网络模型不仅能够获得超过最先进方法的结果，其在真实场景的表现也很理想。不过该方法仍然有一些局限性。一方面是使用SH表示光照的局限性，使用SH表示的光照往往会忽略掉一些高频信息，这对于具有镜面反射表面的物体来说很不友好。另一方面是仅使用图片预测光照时，对输入信息的依赖比较严重，如果输入图片既没有拍摄到场景的光照也没有拍摄到能推理出光照的阴影，则光照估计的效果很可能会不太理想。图片\todo{图片}展示了一种因为这两种局限性导致的失败情况。

使用本文的方法在利用前后置摄像头估计光照时会有一个特定的问题，就是人脸经常会出现在前置摄像头中。比较好的解决办法是用户平移一下手机或者移动一下头部，来通过前置相机获取到更丰富的场景。不过，出现在前置摄像头中的人脸并不能完全视为光照估计问题的一个阻碍。在相关工作中提到，一些研究者使用人脸作为标志物，辅助估计场景的光照。这些工作为基于前后摄像头估计光照的方法提供了一个新的思路————可以将基于人脸的光照估计方法嵌入到本文的方法中，从前置相机的人脸和后置相机的普通图片中共同恢复场景光照，这也是进一步的工作之一。
\section{本章总结}
从有限的图像信息估计出整个场景的光照分布非常复杂。从图像（Image）反推出光照（Light）是一个严重的不适定（ill-posed)问题。相对于整个场景，有限视野的图像不仅包含的信息有限，而且在不同的条件下拍摄的彩色图像可能存在很多误差。这些都会对光照估计造成一定程度的干扰，增加光照估计的难度。

为了降低问题的难度，研究者们尝试对该问题进行约束或简化。传统方法通常增加输入的信息或者减少要估计的光照模型规模。例如增加深度信息、几何信息，或者使用球形谐波模型、Sun-Sky物理模型表示场景的光照等。近年来，深度学习也被应用在光照估计问题当中，不过，目前已有的深度学习方法也有一定的局限性。训练一个鲁棒的神经网络往往需要大量的数据，而目前用于光照估计问题的数据集比较有限，如SUN360\cite{xiao2012recognizing}和Laval Indoor\cite{gardner2017learning}等很难在规模和质量上同时到达训练深度神经网络的要求。

在这样的背景下，本文在基于深度学习的光照估计中的两个方向开展研究。其一是构建一个具有一定规模和质量光照估计的数据集。其二是对深度网络模型进行研究，这也是本章的主要内容。

本文提出使用前两张相对视角的图片作为光照估计的输入。这两张图片多由相机的前后置摄像头拍摄，使用前后摄像头同时拍摄两张照片不仅不会增加获取图片的步骤，还可以极大地降低光照估计的难度。现代移动设备几乎都包含前后至少两个摄像头，因此本文所提方法对于智能手机应用来说有着很大的实际意义。

接着介绍了使用球形谐波技术表示光照的方法，以及这种表示方式用于光照估计问题的优点，并基于此提出一种新的损失函数——render loss。通过将可导的一部分渲染过程连接到卷积神经网络中，增加对渲染结果的监督，进而达到优化光照估计效果的作用。

随后展示了本文所构建的基于深度学习的光照估计网络模型，该网络模型使用两张图片作为输入，估计预测出场景中光照对应的球形谐波系数。目前该方法不仅已经取得了超过state-of-the-art的结果，它在真实场景的中的表现也非常理想。

最后，也是本章内容的核心部分，对深度学习模型的各个模块、损失函数、运行性能、局限性等进行了十分详尽的实验和分析。通过几十组对比实验深入探索了使用不同网络结构的特点和对光照估计结果的影响。这些实验和分析对以后的深度学习、光照估计工作来说有着一定的指导意义。